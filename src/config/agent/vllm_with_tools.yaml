# vLLM Backend with All Tools Enabled
# Example configuration for vLLM with code, search, and mind_map tools

backend: "vllm"

model_path: "/path/to/your/model"  # Update this path
tokenizer_path: null  # Will use model_path if null

vllm:
  tensor_parallel_size: 1
  gpu_memory_utilization: 0.9

generation:
  temperature: 0.7
  top_p: 1.0
  max_tokens: 2048
  max_new_tokens: 2048

tools:
  enabled: true
  available: ["code", "search", "mind_map"]
  
  code:
    model: null  # Uses main model if null
    working_dir: "./tmp"
    timeout: 10
  
  search:
    bing_subscription_key: null  # Set your Bing API key
    bing_endpoint: "https://api.bing.microsoft.com/v7.0/search"
    top_k: 10
    use_jina: true
    jina_api_key: null
  
  mind_map:
    working_dir: "./local_mem"
    initial_content: ""

tool_calling:
  format: "json"
  max_iterations: 5

system_prompt: "You are a helpful AI assistant with access to various tools for code execution, web search, and knowledge graph queries."

