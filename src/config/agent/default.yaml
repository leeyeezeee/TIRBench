# Default LLM Agent Configuration
# This file contains default settings for the LLM Agent

# Backend selection: vllm, sglang, transformers, remote_api
backend: "vllm"

# Model configuration
model_path: ""  # Local model path (required for vllm/transformers)
tokenizer_path: null  # Optional, defaults to model_path
remote_model: null  # Model name for remote_api (e.g., "gpt-4o", "claude-3.5-sonnet")

# Backend-specific settings
vllm:
  tensor_parallel_size: 1
  gpu_memory_utilization: 0.9

transformers:
  device: "cuda"  # cuda, cpu, npu:0
  device_map: null  # "auto" for automatic device mapping

sglang:
  api_base: "http://127.0.0.1:30000"  # SGLang API base URL
  api_key: null  # Optional API key
  concurrency: 8  # Number of concurrent requests

# Generation parameters
generation:
  temperature: 0.7
  top_p: 1.0
  max_tokens: 2048
  max_new_tokens: 2048

# Tool configuration
tools:
  enabled: true  # Enable/disable tool calling
  available: []  # List of tools to enable: ["code", "search", "mind_map"]
  
  # Tool-specific settings
  code:
    model: null  # Model for code generation (if different from main model)
    working_dir: "./tmp"
    timeout: 10  # Code execution timeout in seconds
  
  search:
    bing_subscription_key: null  # Required for search tool
    bing_endpoint: "https://api.bing.microsoft.com/v7.0/search"
    top_k: 10  # Number of search results to return
    use_jina: true  # Use Jina for page content extraction
    jina_api_key: null  # Optional Jina API key
    max_doc_len: 1000  # Maximum document length
  
  mind_map:
    working_dir: "./local_mem"
    initial_content: ""  # Initial content to insert into graph

# Tool call parsing
tool_calling:
  format: "json"  # json, function_call, auto
  max_iterations: 5  # Maximum tool call iterations per request

# System prompt template (optional)
system_prompt: null

